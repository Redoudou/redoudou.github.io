---
published: false
---
## Journey to train my own Stable Diffusion

My goal is to train my own AI model using photos of myself. 
Stable Diffuion is the open source text to image model that I found. There is a lot of guide an tutorials. 
The process requires a lot of ressources and I dont want to spin up a server for this. 
I decided to use the service [RunDiffusion.](https://app.rundiffusion.com/)
- 1$ per hours
- 35$/months to have access to creator mode and advanced extension

It's a no brainer. 

For the rest I am going to use
- [automatic1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) the web UI of SD. 
- [Dreambooth](https://dreambooth.github.io/) to train my model
20 photos of my in 512 by 512.
- [Euler A sampler to train my model](https://stable-diffusion-ui.github.io/docs/samplers/)



To do this I watched a lot of tutorials but 2 stood out.
- [Reddit post about custom embedding](https://www.reddit.com/r/StableDiffusion/comments/zxkukk/detailed_guide_on_training_embeddings_on_a/?utm_source=embedv2&utm_medium=post_embed&utm_content=action_bar&embed_host_url=https%3A%2F%2Flearn.rundiffusion.com%2Ftraining-embeddings%2F)
- [This great 3hours tutorial from Revolved](https://www.youtube.com/watch?v=IPI7QmMOUU8&)

Test on going stay put.

![Screenshot 2023-06-09 at 18.17.40.png]({{site.baseurl}}/_posts/Screenshot 2023-06-09 at 18.17.40.png)


